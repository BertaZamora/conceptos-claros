{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduccion_RNNs.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzIZlVDhoGmvzeTZiUWvS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raulbenitez/conceptosclaros_ML/blob/master/Introduccion_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31P_wKoDQ1_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c38eb496-7b2c-4b5f-bcf7-5ea12e35c885"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsYoA3TcKaPm",
        "colab_type": "text"
      },
      "source": [
        "Redes Neuronales Recurrentes (RNNs):\n",
        "\n",
        "Son redes neuronales con una unidad de memoria que permite procesar datos de naturaleza secuencial:\n",
        "- Señales temporales (audio, series temporales, etc.)\n",
        "- Texto (secuencias encadanadas de caracteres)\n",
        "- Vídeo\n",
        "\n",
        "Las RNN tienen una unidad de memoria que permite ser entrenada sin problemas de estabilidad al aplicar el algoritmo de retro-poropagación. La unidad de memoria más usual es la Long Short-Term Memory (LSTM), que constan de tres puertas que controlan cuándo el dato entra (input gate), cuándo se sobreescribe (forget gate) y cuándo se transmite a la salida (output gate). \n",
        "\n",
        "La estructura es la siguiente:\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1naVymYKjg0mbjI0PTZ4JJmGd5orKHY4j)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTb5njZHMuxW",
        "colab_type": "text"
      },
      "source": [
        "# Ejemplo 1: Clasificación de críticas de películas en IMDB:\n",
        "\n",
        "En este caso los datos consisten en fragmentos de texto en los que usuarios de IMDB escriben su opinión sobre una determinada película. El objectivo es clasificar el comentario como positivo o negativo. \n",
        "\n",
        "Los datos tienen las características siguientes:\n",
        "\n",
        "- Los 80 primeras palabras de cada opinión. si la opinión tiene menos de 80 palabras, se aplica un relleno para que llegue a 80 y así todas las críticas tengan el mismo tamaño. \n",
        "\n",
        "- El número máximo de palabras distintas se limita a 20000. La codificación de las palabras no se hace con un vector de 20000 bits porque sería demasiado ineficiente. La primera capa de la red neuronal (capa de proyección) proyecta los datos a un espacio de dimensionalidad reducida (vocabulario reducido de 128 dimesniones).\n",
        "\n",
        "En la red que se construye en el ejemplo siguiente hay tres capas: la de proyección, que reduce el vocabulario a un espacio de ciento veintiocho dimensiones; la LSTM, con factor de abandono incluido; y la capa de salida, en este caso con una sola unidad porque la respuesta en este caso es binaria.\n",
        "\n",
        "La información detallada sobre la base de datos imdb se puede consultarse en https://keras.io/api/datasets/imdb/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk6TIvIV1sf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "outputId": "91b02987-a299-4e5d-cb11-69fa0e1f862c"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "\n",
        "# Numero de palabras distintas usadas como maximo\n",
        "max_features = 20000\n",
        "# De cada opinion se toman las 80 primeras palabras\n",
        "maxlen = 80  \n",
        "# Y las opiniones se agrupan en lotes de 32\n",
        "batch_size = 32\n",
        "\n",
        "# Cargar los datos\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "# Empaquetar los ejemplos en matrices cuadradas (rellenar)\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "# Crear el modelo con tres capas\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar y entrenar\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluar con los datos de test\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Build model...\n",
            "Train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.4628 - accuracy: 0.7822 - val_loss: 0.3855 - val_accuracy: 0.8318\n",
            "Epoch 2/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.3112 - accuracy: 0.8722 - val_loss: 0.3925 - val_accuracy: 0.8339\n",
            "Epoch 3/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.2275 - accuracy: 0.9120 - val_loss: 0.4276 - val_accuracy: 0.8307\n",
            "Epoch 4/15\n",
            "25000/25000 [==============================] - 130s 5ms/step - loss: 0.1647 - accuracy: 0.9372 - val_loss: 0.4753 - val_accuracy: 0.8164\n",
            "Epoch 5/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.1196 - accuracy: 0.9570 - val_loss: 0.5845 - val_accuracy: 0.8264\n",
            "Epoch 6/15\n",
            "25000/25000 [==============================] - 130s 5ms/step - loss: 0.0827 - accuracy: 0.9704 - val_loss: 0.6370 - val_accuracy: 0.8235\n",
            "Epoch 7/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0703 - accuracy: 0.9754 - val_loss: 0.6629 - val_accuracy: 0.8193\n",
            "Epoch 8/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0558 - accuracy: 0.9822 - val_loss: 0.9769 - val_accuracy: 0.8080\n",
            "Epoch 9/15\n",
            "25000/25000 [==============================] - 130s 5ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.8527 - val_accuracy: 0.8133\n",
            "Epoch 10/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.8349 - val_accuracy: 0.8103\n",
            "Epoch 11/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 0.8896 - val_accuracy: 0.8064\n",
            "Epoch 12/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.9198 - val_accuracy: 0.8077\n",
            "Epoch 13/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 1.0094 - val_accuracy: 0.8113\n",
            "Epoch 14/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 1.0392 - val_accuracy: 0.8057\n",
            "Epoch 15/15\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.1504 - val_accuracy: 0.8077\n",
            "25000/25000 [==============================] - 21s 832us/step\n",
            "Test score: 1.1504111164689064\n",
            "Test accuracy: 0.8077200055122375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhg-ZSrZ2bgH",
        "colab_type": "text"
      },
      "source": [
        "# Ejemplo 2: Predicción del frame siguiente:\n",
        "\n",
        "En este ejemplo se combinan las redes recurrentes y las redes convolucionales para resolver un problema de predicción del frame siguiente en secuencias de imágenes generadas artificialmente. Más detalles en:\n",
        "\n",
        "from https://keras.io/examples/vision/conv_lstm/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1xWCVkDn2U3j"
      },
      "source": [
        "# Next-frame prediction with Conv-LSTM\n",
        "\n",
        "**Author:** [jeammimi](https://github.com/jeammimi)<br>\n",
        "**Date created:** 2016/11/02<br>\n",
        "**Last modified:** 2020/05/01<br>\n",
        "**Description:** Predict the next frame in a sequence using a Conv-LSTM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRL88eAy2U3m"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This script demonstrates the use of a convolutional LSTM model.\n",
        "The model is used to predict the next frame of an artificially\n",
        "generated movie which contains moving squares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wi2UcOaY2U3o"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ra5K-Yrf2U3r",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pylab as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgcr7RLR2U3x"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We create a model which take as input movies of shape\n",
        "`(n_frames, width, height, channels)` and returns a movie\n",
        "of identical shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2S4DcpQ2U3y",
        "colab": {}
      },
      "source": [
        "seq = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(\n",
        "            shape=(None, 40, 40, 1)\n",
        "        ),  # Variable-length sequence of 40x40x1 frames\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv3D(\n",
        "            filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "seq.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jbTKBOEb2U31"
      },
      "source": [
        "## Generate artificial data\n",
        "\n",
        "Generate movies with 3 to 7 moving squares inside.\n",
        "The squares are of shape 1x1 or 2x2 pixels,\n",
        "and move linearly over time.\n",
        "For convenience, we first create movies with bigger width and height (80x80)\n",
        "and at the end we select a 40x40 window.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DZCk3wd_2U32",
        "colab": {}
      },
      "source": [
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Add 3 to 7 moving squares\n",
        "        n = np.random.randint(3, 8)\n",
        "\n",
        "        for j in range(n):\n",
        "            # Initial position\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            # Direction of motion\n",
        "            directionx = np.random.randint(0, 3) - 1\n",
        "            directiony = np.random.randint(0, 3) - 1\n",
        "\n",
        "            # Size of the square\n",
        "            w = np.random.randint(2, 4)\n",
        "\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[\n",
        "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
        "                ] += 1\n",
        "\n",
        "                # Make it more robust by adding noise.\n",
        "                # The idea is that if during inference,\n",
        "                # the value of the pixel is not exactly one,\n",
        "                # we need to train the model to be robust and still\n",
        "                # consider it as a pixel belonging to a square.\n",
        "                if np.random.randint(0, 2):\n",
        "                    noise_f = (-1) ** np.random.randint(0, 2)\n",
        "                    noisy_movies[\n",
        "                        i,\n",
        "                        t,\n",
        "                        x_shift - w - 1 : x_shift + w + 1,\n",
        "                        y_shift - w - 1 : y_shift + w + 1,\n",
        "                        0,\n",
        "                    ] += (noise_f * 0.1)\n",
        "\n",
        "                # Shift the ground truth by 1\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[\n",
        "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
        "                ] += 1\n",
        "\n",
        "    # Cut to a 40x40 window\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    return noisy_movies, shifted_movies\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tlCjgLx-2U39"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ls8Wf5pr2U3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34ecf7ee-73b7-4c5c-f967-412360310393"
      },
      "source": [
        "epochs = 200\n",
        "\n",
        "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
        "seq.fit(\n",
        "    noisy_movies[:1000],\n",
        "    shifted_movies[:1000],\n",
        "    batch_size=10,\n",
        "    epochs=epochs,\n",
        "    verbose=2,\n",
        "    validation_split=0.1,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LChewtHp2U4B"
      },
      "source": [
        "## Test the model on one movie\n",
        "\n",
        "Feed it with the first 7 positions and then\n",
        "predict the new positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8EnK8-FK2U4C",
        "colab": {}
      },
      "source": [
        "movie_index = 1004\n",
        "track = noisy_movies[movie_index][:7, ::, ::, ::]\n",
        "\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "\n",
        "# And then compare the predictions\n",
        "# to the ground truth\n",
        "track2 = noisy_movies[movie_index][::, ::, ::, ::]\n",
        "for i in range(15):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, \"Predictions !\", fontsize=20, color=\"w\")\n",
        "    else:\n",
        "        ax.text(1, 3, \"Initial trajectory\", fontsize=20)\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, \"Ground truth\", fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[movie_index][i - 1, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig(\"%i_animate.png\" % (i + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfiSipaP_hwT",
        "colab_type": "text"
      },
      "source": [
        "# Ejemplo 3: Predicción de series temporales univariadas con RNNs\n",
        "\n",
        "En este ejemplo se utilizan las RNNs con unidades de memoria LSTM para hacer predicción a un paso con series temporales univariadas. \n",
        "\n",
        "https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
        "\n",
        "\n",
        "Los datos constan de los datos mensuales de ventas de champú durante un período de 3 años y por tanto incluyen un total de 36 observaciones. Se puede acceder al fichero de datos en https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A9LBuXmRKCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_data = '/content/gdrive/My Drive/data_course/shampoo.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx2SCQg4_oDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "a04a7968-fa78-4655-b658-fe82b28f3d30"
      },
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "import numpy\n",
        " \n",
        "# date-time parsing function for loading the dataset\n",
        "def parser(x):\n",
        "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
        " \n",
        "# frame a sequence as a supervised learning problem\n",
        "def timeseries_to_supervised(data, lag=1):\n",
        "\tdf = DataFrame(data)\n",
        "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
        "\tcolumns.append(df)\n",
        "\tdf = concat(columns, axis=1)\n",
        "\tdf.fillna(0, inplace=True)\n",
        "\treturn df\n",
        " \n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn Series(diff)\n",
        " \n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "\treturn yhat + history[-interval]\n",
        " \n",
        "# scale train and test data to [-1, 1]\n",
        "def scale(train, test):\n",
        "\t# fit scaler\n",
        "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\tscaler = scaler.fit(train)\n",
        "\t# transform train\n",
        "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
        "\ttrain_scaled = scaler.transform(train)\n",
        "\t# transform test\n",
        "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
        "\ttest_scaled = scaler.transform(test)\n",
        "\treturn scaler, train_scaled, test_scaled\n",
        " \n",
        "# inverse scaling for a forecasted value\n",
        "def invert_scale(scaler, X, value):\n",
        "\tnew_row = [x for x in X] + [value]\n",
        "\tarray = numpy.array(new_row)\n",
        "\tarray = array.reshape(1, len(array))\n",
        "\tinverted = scaler.inverse_transform(array)\n",
        "\treturn inverted[0, -1]\n",
        " \n",
        "# fit an LSTM network to training data\n",
        "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
        "\tX, y = train[:, 0:-1], train[:, -1]\n",
        "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
        "\tmodel.add(Dense(1))\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\tfor i in range(nb_epoch):\n",
        "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "\t\tmodel.reset_states()\n",
        "\treturn model\n",
        " \n",
        "# make a one-step forecast\n",
        "def forecast_lstm(model, batch_size, X):\n",
        "\tX = X.reshape(1, 1, len(X))\n",
        "\tyhat = model.predict(X, batch_size=batch_size)\n",
        "\treturn yhat[0,0]\n",
        " \n",
        "# load dataset\n",
        "series = read_csv(folder_data, header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        " \n",
        "# transform data to be stationary\n",
        "raw_values = series.values\n",
        "diff_values = difference(raw_values, 1)\n",
        " \n",
        "# transform data to be supervised learning\n",
        "supervised = timeseries_to_supervised(diff_values, 1)\n",
        "supervised_values = supervised.values\n",
        " \n",
        "# split data into train and test-sets\n",
        "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
        " \n",
        "# transform the scale of the data\n",
        "scaler, train_scaled, test_scaled = scale(train, test)\n",
        " \n",
        "# fit the model\n",
        "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
        "# forecast the entire training dataset to build up state for forecasting\n",
        "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
        "lstm_model.predict(train_reshaped, batch_size=1)\n",
        " \n",
        "# walk-forward validation on the test data\n",
        "predictions = list()\n",
        "for i in range(len(test_scaled)):\n",
        "\t# make one-step forecast\n",
        "\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
        "\tyhat = forecast_lstm(lstm_model, 1, X)\n",
        "\t# invert scaling\n",
        "\tyhat = invert_scale(scaler, X, yhat)\n",
        "\t# invert differencing\n",
        "\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
        "\t# store forecast\n",
        "\tpredictions.append(yhat)\n",
        "\texpected = raw_values[len(train) + i + 1]\n",
        "\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
        " \n",
        "# report performance\n",
        "rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "# line plot of observed vs predicted\n",
        "pyplot.plot(raw_values[-12:])\n",
        "pyplot.plot(predictions)\n",
        "pyplot.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Month=1, Predicted=388.778925, Expected=339.700000\n",
            "Month=2, Predicted=410.279774, Expected=440.400000\n",
            "Month=3, Predicted=451.441214, Expected=315.900000\n",
            "Month=4, Predicted=379.022264, Expected=439.300000\n",
            "Month=5, Predicted=449.760822, Expected=401.300000\n",
            "Month=6, Predicted=481.367683, Expected=437.400000\n",
            "Month=7, Predicted=427.988861, Expected=575.500000\n",
            "Month=8, Predicted=697.883343, Expected=407.600000\n",
            "Month=9, Predicted=492.988652, Expected=682.000000\n",
            "Month=10, Predicted=720.946365, Expected=475.300000\n",
            "Month=11, Predicted=503.769422, Expected=581.300000\n",
            "Month=12, Predicted=879.713950, Expected=646.900000\n",
            "Test RMSE: 155.967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu511M4IKYkD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm49O_UU_ozO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}